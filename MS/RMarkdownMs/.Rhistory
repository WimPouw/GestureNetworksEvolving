a <- ggplot(ned, aes(x= generation, y = entropyWfunctions, color = chain)) + geom_point() + geom_smooth(method= "lm", size=0.1, alpha=0.02)+ geom_smooth(method= "lm", color = "red") + theme_bw()+ ggtitle("entropy within functional grouping") + theme(legend.position = "none")+ scale_color_brewer(palette = "Dark2")
b <- ggplot(ned, aes(x= generation, y = entropyWthemes, color = chain)) + geom_point()+ geom_smooth(method= "lm", size=0.1, alpha=0.02) + geom_smooth(method= "lm", color = "red") + ggtitle("entropy within theme grouping") +theme_bw()+ theme(legend.position = "none") + scale_color_brewer(palette = "Dark2")
grid.arrange(a,b, nrow =1)
cor.test(ned$generation, ned$entropyWfunctions)
basem1 <- lme(entropyWfunctions~1, data = ned, random = ~generation|chain, method = "ML", na.action = na.exclude)
model1 <- lme(entropyWfunctions~generation, data = ned, random = ~generation|chain, method = "ML", na.action = na.exclude)
basem1 <- lme(entropyWfunctions~1, data = ned, random = ~1|chain, method = "ML", na.action = na.exclude)
model1 <- lme(entropyWfunctions~generation, data = ned, random = ~1|chain, method = "ML", na.action = na.exclude)
summary(model1)
basem1 <- lme(entropyWfunctions~1, data = ned, random = ~1+generation|chain, method = "ML", na.action = na.exclude)
model1 <- lme(entropyWfunctions~generation, data = ned, random = ~1+generation|chain, method = "ML", na.action = na.exclude)
basem1 <- lme(entropyWfunctions~1, data = ned, random = ~1|chain, method = "ML", na.action = na.exclude)
model1 <- lme(entropyWfunctions~generation, data = ned, random = ~1|chain, method = "ML", na.action = na.exclude)
basem1 <- lme(entropyWthemes~1, data = ned, random = ~1|chain, method = "ML", na.action = na.exclude)
model1 <- lme(entropyWthemes~generation, data = ned, random = ~1|chain, method = "ML", na.action = na.exclude)
summary(model1)
#not reliable
basem1 <- lme(entropyWthemes~1, data = ned, random = ~1+generation|chain, method = "ML", na.action = na.exclude)
model1 <- lme(entropyWthemes~generation, data = ned, random = ~1+generation|chain, method = "ML", na.action = na.exclude)
basem1 <- lme(entropyWthemes~1, data = ned, random = ~generation|chain, method = "ML", na.action = na.exclude)
model1 <- lme(entropyWthemes~generation, data = ned, random = ~generation|chain, method = "ML", na.action = na.exclude)
install.packages("citr")
install.packages("citr")
writeLines('PATH="${RTOOLS40_HOME}\\usr\\bin;${PATH}"', con = "~/.Renviron")
getwd
setwd("E:/research_EmergingLanguageKirby/REVISION_COGSCI/RMarkdownMs_revision")
dirname(getwd())
library("papaja")     #papaja::apa6_pdf papaja::apa6_word
library(ggplot2)      #plotting
library(gridExtra)    #plotting (constructing multipanel plots)
library(ggExtra)      #plotting (adding distributions)
library(RColorBrewer) #plotting (color schemes)
library(dtw)          #dynamic time warping functions
library(effsize)      #effect sizes calculations
library(igraph)       #network graphing and analysis (network entropy)
library(cluster)      #cluster analysis (agglomerative clustering coefficient)
library(nlme)         #mixed linear regression
library(signal)       #for butterworth filter
library(pracma)       #for peak finding
library(r2glmm)       #mixed regression R^2
library(DescTools)    #Entropy calculation of the original motamedi data
library(entropy)      #Entropy calculations
library(EMAtools)     #cohen's d for mixed regression predictors
library(tsne)         #visualization for networks
library(cowplot)      #plotting aesthetics
library(scales)       #functions rescaling variables
library(stringr)          #string manipulation
library(parallelsugar)    #for parallel computing
library(clValid)      #clustering
library(MASS)         #clustering
# Seed for random number generation
# This is for example important for dimensionality reduction t-sne used for
# plotting
set.seed(42)
knitr::opts_chunk$set(cache.extra = knitr::rand_seed)
#prepare the data
#time series data (ts): This file contains all the gesture time series and relevant info about the gesture (chain etc)
#matrices data: This is the folder where all the gesture network matrices are stored and are created in the code chunk below
#meta: This contains the original data from Motamedi where e.g., gesture codes, unique information units are given for each gesture
#SET FOLDERS: !!!PLEASE CHANGE TO OWN FOLDER STRUCTURE FOR CODE TO RUN APPROPRIATELY!!!
basefolder <- dirname(getwd())
ts <- read.csv(paste0(basefolder, "/Experiment1/Data/ts_exp1.csv"))
matrices_data <- paste0(basefolder, "/Experiment1/Data/DistanceMatrices/")
plotfolder <- paste0(basefolder, "/Experiment1/Plots")
#load in original METAdata Motamedi into time series
meta <- read.csv(paste0(basefolder, "/experiment1/Data/ex1.csv"))
#change the naming in the meta file and time so that it overlaps with the naming in the time series file
meta$target <- gsub(" ", "_", meta$target)
ts$object <- as.character(ts$object)
meta$target[meta$target == "to_take_a_photo"] <- "take_photo"
#loop through object names in the time series file, match with meta naming, and change to time series naming
for(i in unique(ts$object))
{
meta$target[grep(i, meta$target)] <- i
}
#recompute entropy Motamedi
meta$uniq_codestring <- NA
#first only keep unique human-coded information elements in each gesture (this is where entropy is calculated on)
for(r in 1:nrow(meta))
{
strr <- c(strsplit(as.character(meta$code_string[r]), split = ",")[[1]]) # get a vector with all elements
if(length(strr) > 0) #if there is more than one element
{
meta$uniq_codestring[r] <- paste0(strr[!duplicated(strr)], collapse = ',') #remove duplicates and combine them in a single string again, then save into unique code string
}
}
#compute entropy on the concatenated list for gesture information units per participant
meta$entropy <- NA #initalize variable which will contain ppn-level entropy, it will be saved in the metadataset
for(ppn in unique(meta$participant))
{
gstring     <- paste0(as.character(meta$uniq_codestring[meta$participant == ppn]),collapse = ',')
gstring     <- as.data.frame(strsplit(gstring, split = ","))
gstring[,1] <- as.numeric(factor(gstring[,1]))
meta$entropy[meta$participant==ppn]     <- Entropy(gstring[,1]) #add entropy measure to Motamedi meta file
}
#load in time series object for each gesture the video_length, number of reps, guess time, code length, code_string(entropy calc)
unique_videos <- unique( paste0(ts$ppn, ts$object)) #make an object where we can identify each unique gesture in the dataset
#make new variables in in the time series files
ts$ann_guesstime <- ts$ann_gcode <- ts$ann_reps <-  ts$ann_inf_units <-ts$segments <- ts$ann_entropy  <- NA
#loop through all videos and load in relevant data from the meta files so that Time series data have this info too
for(v in unique_videos)
{
condts <- (paste0(ts$ppn, ts$object)==v) #set condition for selection time series
condmet <- (paste0(meta$participant, meta$target)==v) #set condition for selection time series
#load in the meta data into time series object so that this information can be easily retrieved
#when using these objects for analysis
if(TRUE %in% condmet)
{
ts$ann_guesstime[condts]  <- unique(meta$guess_time[condmet])
ts$ann_verb[condts]       <- as.character(unique(meta$verb[condmet]))
ts$ann_gcode[condts]      <- as.character(unique(meta$code_string[condmet]))
ts$ann_reps[condts]       <- unique(meta$num_reps[condmet])
ts$ann_inf_units[condts]  <- unique(meta$code_len[condmet])
ts$segments[condts]       <- unique(meta$num_reps[condmet])+unique(meta$code_len[condmet])
ts$ann_entropy[condts]    <- unique(meta$entropy[condmet])
}
}
#FUNCTION extractR.traces: we often need to extract the relevant movement traces from the dataset for input for the Multivariate DTW
#the relevant z-scaled and centered x,y, traces are left and right hand movement, head movement
#this function extracts these traces to be used as input for DTW
extractR.traces <- function(dat)
{
dat <- data.frame(dat)
ts1 <- cbind( as.vector(scale(dat$x_index_left, center = TRUE)),
as.vector(scale(dat$y_index_left, center = TRUE)),
as.vector(scale(dat$x_index_right, center = TRUE)),
as.vector(scale(dat$y_index_right, center = TRUE)),
as.vector(scale(dat$x_wrist_left, center = TRUE)),
as.vector(scale(dat$y_wrist_left, center = TRUE)),
as.vector(scale(dat$x_wrist_right, center = TRUE)),
as.vector(scale(dat$y_wrist_right, center = TRUE)),
as.vector(scale(dat$x_nose, center = TRUE)),
as.vector(scale(dat$y_nose, center = TRUE)))
}
#FUNCTION DTW.compare:  This function performs the multidimensional dynamic time warping (D) score
#It takes two multivariable time series (see extractR.traces) as argument, and it takes as argument whether only hands should be compared
DTW.compare <- function(TS1, TS2, manualonly)
{
#make sure that if there is nothing detected than set to 0
TS1 <- ifelse(is.nan(TS1), 0, TS1)
TS2 <- ifelse(is.nan(TS2), 0, TS2)
#perform the dynamic time warping, extract the distance, and then sum the score
distancedtw <-  dtw(  TS1[,1:2],   TS2[,1:2])$normalizedDistance +
dtw(  TS1[,3:4],   TS2[,3:4])$normalizedDistance +
dtw(  TS1[,5:6],   TS2[,5:6])$normalizedDistance +
dtw(  TS1[,7:8],   TS2[,7:8])$normalizedDistance +
dtw(  TS1[,9:10],   TS2[,9:10])$normalizedDistance
#do the same procedure but only for the index and wrist traces (will be use to compare performance of different body points)
if(manualonly == "manual_only")
{
distancedtw <-  dtw(  TS1[,1:2],   TS2[,1:2])$normalizedDistance +
dtw(  TS1[,3:4],   TS2[,3:4])$normalizedDistance +
dtw(  TS1[,5:6],   TS2[,5:6])$normalizedDistance +
dtw(  TS1[,7:8],   TS2[,7:8])$normalizedDistance
}
return(distancedtw)
}
#dimensionless smoothness measure
smooth.get <- function(velocity) #Hogan & Sternad formula
{
if(!all(velocity ==0))
{
velocity <- as.vector(scale(velocity))
acceleration <- butter.it(diff(velocity))
jerk         <- butter.it(diff(acceleration))
integrated_squared_jerk <- sum(jerk^2)
max_squaredvelocity <- max(velocity^2)
D3 <- (length(velocity))^3
jerk_dimensionless <-  integrated_squared_jerk*(D3/max_squaredvelocity)
smoothness <- jerk_dimensionless
}
if(all(velocity ==0)) #if all zero, this
{
smoothness <- NA
}
return(smoothness)
}
#butterworth filter
butter.it <- function(x)
{bf <- butter(1, 1/33, type="low")
x <- as.numeric(signal::filter(bf, x))}
#kinematic feature extraction:
#THIS FUNCTION EXTRACTS FOR ALL keypoints the: submovements, intermittency (smoothness), rhythm,
#temporal variability (rhythmicity), gesture space
kin.get <- function(MT)
{
MT <- data.frame(MT)
#perform submovement analysis(using findpeaks function), and also compute rhythm and temporal variability from it
#extract peaks from velocity time series
peaksnose       <- findpeaks(as.vector(scale(MT$velocity_nose)), minpeakdistance = 8, minpeakheight = -1, threshold=0.1)
rhythmnose    <- abs(diff(MT$time_ms[peaksnose[,2]]))/1000 #compute interval in time between peaks
#extract peaks from velocity time series
peaksleft_w     <- findpeaks(as.vector(scale(MT$velocity_left_w)), minpeakdistance = 8, minpeakheight = -1, threshold=0.1)
rhythmleft_w    <- abs(diff(MT$time_ms[peaksleft_w[,2]]))/1000 #compute interval in time between peaks
#extract peaks from velocity time series
peaksright_w    <- findpeaks(as.vector(scale(MT$velocity_right_w)), minpeakdistance = 8, minpeakheight = -1,threshold=0.1)
rhythmright_w    <- abs(diff(MT$time_ms[peaksright_w[,2]]))/1000 #compute interval in time between peaks
#extract peaks from velocity time series
peaksleft_i     <- findpeaks(as.vector(scale(MT$velocity_left)), minpeakdistance = 8, minpeakheight = -1,threshold=0.1)
rhythmleft_i    <- abs(diff(MT$time_ms[peaksleft_i[,2]]))/1000 #compute interval in time between peaks
#extract peaks from velocity time series
peaksright_i    <- findpeaks(as.vector(scale(MT$velocity_right)), minpeakdistance = 8, minpeakheight = -1,threshold=0.1)
rhythmright_i    <- abs(diff(MT$time_ms[peaksright_i[,2]]))/1000 #compute interval in time between peaks
#extract temporal variability from rhythm intervals
rhythmicity <- NA
rhythmicity <- c(sd(rhythmnose, na.rm=TRUE), sd(rhythmleft_w, na.rm = TRUE), sd(rhythmright_w, na.rm= TRUE), sd(rhythmleft_i, na.rm =TRUE), sd(rhythmright_i, na.rm = TRUE))
rhythmicity <- mean(rhythmicity, na.rm= TRUE)
if(is.nan(rhythmicity)){rhythmicity <- NA} #if there are no intervals to extract rhythm for set at NA (rather than nan)
#compute average rhythm tempo
rhythm <- NA
rhythm <- c(rhythmnose, rhythmleft_w, rhythmright_w, rhythmleft_i,rhythmright_i)
rhythm <- mean(rhythm, na.rm= TRUE)
if(is.nan(rhythm)){rhythm <- NA} #if there are no intervals to extract rhythm for set at NA
#compute total submovements from all keypoints
submovements <- sum(c(nrow(peaksnose), nrow(peaksleft_w), nrow(peaksright_w), nrow(peaksleft_i),                  nrow(peaksright_i), na.rm=TRUE))
#compute average intermittency (referred to here as smoothness) of all keypoints (use function smooth.get given above)
smoothness <- mean(c(smooth.get(MT$velocity_nose), smooth.get(MT$velocity_left_w), smooth.get(MT$velocity_left_w),  smooth.get(MT$velocity_left), smooth.get(MT$velocity_right)))
#compute average gesture space used by the gesture
gspace <- mean(c( (max(MT$x_nose)-min(MT$x_nose))*(max(MT$y_nose)-min(MT$y_nose)),
(max(MT$x_index_left)-min(MT$x_index_left))*(max(MT$y_index_left)-min(MT$y_index_left)),
(max(MT$x_index_right)-min(MT$x_index_right))*(max(MT$y_index_right)-min(MT$y_index_right)),
(max(MT$x_wrist_left)-min(MT$x_wrist_left))*(max(MT$y_wrist_left)-min(MT$y_wrist_left)),
(max(MT$x_wrist_right)-min(MT$x_wrist_right))*(max(MT$y_wrist_right)-min(MT$y_wrist_right))))
gspace <- gspace/1000
#bind everything into a single output object containing all the relevent kinematic features
features <- cbind(submovements, smoothness, gspace, rhythmicity,rhythm)
return(features)
}
#network entropy mean
ent.N <- function(matri)
{
entropym<- graph.adjacency(as.matrix(matri), mode="undirected", weighted=TRUE, diag = FALSE)
entropy <- mean(igraph::diversity(entropym))
return(entropy)
}
library(raster)
#load in the finally edited time series example
mypng <- stack(paste0(plotfolder, "/Concepts/concepts.png"))
plotRGB(mypng,maxpixels=1e500000)
library(raster)
#load in the finally edited time series example
mypng <- stack(paste0(plotfolder, "/MethodPlot/main_method_v3a.png"))
plotRGB(mypng,maxpixels=1e500000)
#plot for checking algorithm
tstemp <- ts              #create a temporary copy of the time series data
tstemp$identifier <- paste0(tstemp$generation, tstemp$ppn, tstemp$chain, tstemp$object)  #make an identifier for each video
dimjerk <- peaks <- vector()
feats <- data.frame()
for(i in unique(tstemp$identifier)) #go through all time series and extract the kinematic features using the custom function
{
cc <- tstemp[tstemp$identifier == i,] #also get the data from human codings (repetitions, infnormation units, and segments)
get <- cbind(kin.get(cc), cc$ann_reps[1], cc$ann_inf_units[1], cc$segments[1])
feats <- rbind.data.frame(feats, get)
}
colnames(feats) <- c(colnames(feats[1:5]), "repetitions", "inf_units", "segments")
feats$smoothness <- log(feats$smoothness)     #this measure tends to explode at high values, so we log scale them
feats$submovements <- log(feats$submovements) #thus measure tends to explode at high values, so we log scale them
#correlations to report (intermittency and rhythm measure)
cx <- cor.test(feats$smoothness, feats$rhythm)
cxt <- c(round(cx$estimate, 2),ifelse(cx$p.value < .001, "< .001", round(cx$p.value, 3)))
#for method jerk plots
#example 1
exm <- ts[ts$time_ms > 0 & ts$generation=="s" & ts$seedsetnum == "arrest2",] #extract sample from the data
exm$velocity_right_w <- as.vector(scale(exm$velocity_right_w)) #z-scale the speed vector
#extract peaks
peaksexm <- findpeaks(exm$velocity_right_w,minpeakdistance = 8,  minpeakheight = -1, threshold=0.1) #apply peakfinder function to the time series, with the same thresholds as our kin.get function given at the custom function section
exm$peak <- ifelse(exm$time_ms %in% exm$time_ms[peaksexm[,2]], exm$velocity_right_w, NA) #save the peak height into the time series by matching with the time
exm$peaktime <- ifelse(exm$time_ms %in% exm$time_ms[peaksexm[,2]], exm$time_ms, NA) #save the peak time into the time series by matching with the time
smoothness <- smooth.get(exm$velocity_right_w) #apply the custom function calculating smoothness
rhythmicity <- sd(abs(diff(exm$time_ms[peaksexm[,2]]))/1000) #compute the st. dev. time interval between peaks, and divide by 1000 ms to get Hz
#left plot
a <- ggplot(exm) + geom_line(aes(x=time_ms, y = velocity_right_w)) +
geom_point(aes(x = peaktime, y = peak), color = "red", size = 2) +
annotate("text", label= paste0("submovements = ", nrow(peaksexm)), x=1750, y=2.15)+
annotate("text", label = paste0("intermittency = ", round(log(smoothness)), round = 2), x=1750, y=1.80) +
annotate("text", label = paste0("temporal var. = ", round(rhythmicity,2)), x=1750, y=1.35) +
xlab("time (ms)") +
ylab("speed right wrist (z-scaled)")+
theme_bw()
#right plot (NOTE, this repeats what is done above)
exm5 <- ts[ts$time_ms > 0 & ts$generation=="5" & ts$chain == "chain5" & ts$seedsetnum == "arrest2" & ts$ppn == "full50",]
exm5$velocity_right_w <- as.vector(scale(exm5$velocity_right_w))
peaksexm5 <- findpeaks(as.vector(scale(exm5$velocity_right_w)),minpeakdistance = 8,  minpeakheight = -1, threshold=0.1)
exm5$peak <- ifelse(exm5$time_ms %in% exm5$time_ms[peaksexm5[,2]], exm5$velocity_right_w, NA)
exm5$peaktime <- ifelse(exm5$time_ms %in% exm5$time_ms[peaksexm5[,2]], exm5$time_ms, NA)
smoothness <- smooth.get(exm5$velocity_right_w)
rhythmicity <- sd(abs(diff(exm5$time_ms[peaksexm5[,2]]))/1000)
b <- ggplot(exm5) + geom_line(aes(x=time_ms, y = velocity_right_w)) +
geom_point(aes(x = peaktime, y = peak), color = "red", size = 2) +
annotate("text", label= paste0("submovements = ", nrow(peaksexm5)), x=3000, y=2.15)+
annotate("text", label = paste0("intermittency = ", round(log(smoothness)), round = 2), x=3000, y=1.80) +
annotate("text", label = paste0("temporal var. = ", round(rhythmicity,2)), x=3000, y=1.35) +
xlab("time (ms)") +
ylab("speed right wrist (z-scaled)")+
theme_bw()
grid.arrange(a,b, nrow=1)
sub_ts <- subset(ts, as.character(generation) == "1")   #keep 1 generation gestures
seeds  <- subset(ts, as.character(generation) ==  "s")  #keep only seed gestures
chainnum <- D <- Dran <- Dman <- Dranman<- vector() #initialize vectors to be filled and combined into data set for statistical analysis
for(chs in unique(sub_ts$chain)) #loop through all the chains (note we are going to make smaller and smaller data sets to loop faster)
{
print(paste0("working on chain: ", chs)) #print something to see progress
sub_ts_temp <-  subset(sub_ts, chain == chs) #make a smaller data.frame for this chain
for(pp in unique(sub_ts_temp$ppn))           #for this chain data loop through participants
{
sub_ts_temp2 <- subset(sub_ts_temp, as.character(ppn) == pp) #make a smaller data.frame for this chain, participant
for(obj in unique(sub_ts_temp2$object))  #make a smaller data.frame for this chain, particpant, object
{
#true pair (make a comparison pair to DTW, with one current reference and the origin seed)
tt1 <- subset(sub_ts_temp2, as.character(ppn) == pp & as.character(object) == obj) #reference data
sobject <- as.character(unique(tt1$seedsetnum))                              #which seed video is was the origin of the current?
tt2 <- subset(seeds, as.character(seedsetnum) ==  sobject)     #get the exact seed based on seed list and object
#random paired (make a comparison pair to DTW, with one current reference and a random [and unrelated] origin seed)
listotherobjects <- unique(sub_ts_temp2$object[sub_ts_temp2$object != obj &
sub_ts_temp2$theme !=  unique(tt1$theme) &
sub_ts_temp2$functional != unique(tt1$functional)]) #subset objects which are not the same reference,theme,                                                                                      and function
pickranobject    <- sample(     listotherobjects , 1)                 #pick randomly an object from that list
tt2r <- subset(seeds, as.character(object) == pickranobject)          #extract random test data
#Extract relevant traces to be inputted for DTW
MT1   <- extractR.traces(tt1)
MT2   <- extractR.traces(tt2)
MT2r  <- extractR.traces(tt2r)
#perform DTW distance calc for actual and random pair
DTWpair    <-  DTW.compare(MT1, MT2, "NA")
DTWranpair <-  DTW.compare(MT1, MT2r, "NA")
#also perform same comparisons for only manual movements (excluding head movements)
DTWpair_man    <-  DTW.compare(MT1, MT2, "manual_only")
DTWranpair_man <-  DTW.compare(MT1, MT2r, "manual_only")
#collect into dataset for statistical analysis
chainnum <- c(chainnum, chs)
D        <- c(D, DTWpair)
Dran     <- c(Dran, DTWranpair)
Dman     <- c(Dman,   DTWpair_man)
Dranman  <- c(Dranman, DTWranpair_man)
}
}
}
#bind into a dataset for statistical analysis of measure accuracy
t <- cbind.data.frame(chainnum,  D)
t2 <- cbind.data.frame(chainnum,  Dran)
tm1 <- cbind.data.frame(chainnum,  Dman)
tm2 <- cbind.data.frame(chainnum,  Dranman)
t$pairtype <- tm1$pairtype <- "true pair"
t2$pairtype  <- tm2$pairtype <- "random pair"
colnames(t) <- colnames(t2) <- colnames(tm1) <-colnames(tm2) <- c("chain", "DTWdistance", "pair")
#compare Distances random-true pairs
mcheck <- rbind.data.frame(t,t2)
test <- t.test(mcheck$DTWdistance~mcheck$pair)
D  <- cohen.d(mcheck$DTWdistance, mcheck$pair)$estimate
diff1 <- mcheck$DTWdistance[mcheck$pair == "random pair"]-mcheck$DTWdistance[mcheck$pair == "true pair"]
#compare Distances random-true pairs for only the manual
mcheckman <- rbind.data.frame(tm1,tm2)
Dman  <- cohen.d(mcheckman$DTWdistance, mcheckman$pair)$estimate
diff2 <- mcheckman$DTWdistance[mcheck$pair == "random pair"]-mcheckman$DTWdistance[mcheck$pair == "true pair"]
#make a dataset that compares differences in head included or head excluded DTW distances
comb <- as.data.frame(c(diff1,diff2))
comb$inc <- c(rep("head included" , length(diff1)), rep("head excluded", length(diff2)))
test_maninc <- t.test(comb[,1]~comb$inc)
tm <- mean(mcheck$DTWdistance[mcheck$pair =="true pair"])
fm <- mean(mcheck$DTWdistance[mcheck$pair =="random pair"])
colors <- brewer.pal(n = 2, name = "Set1")
a <- ggplot(mcheck, aes(x = DTWdistance, color = pair, fill= pair)) + geom_density(size = 2, alpha= 0.2) + geom_vline(xintercept = fm, linetype = "dashed", color = colors[1], size = 2) + geom_vline(xintercept = tm, linetype = "dashed", color = colors[2], size = 2) +
scale_colour_manual(values=colors)+
theme_bw() +  theme(panel.grid.major = element_blank()) + xlab("DTW distance")
a
library(raster)
#load in the finally edited time series example
mypng <- stack(paste0(plotfolder, "/MethodPlot/main_method_v3b.png"))
plotRGB(mypng,maxpixels=1e500000)
mat1 <- read.csv(paste0(matrices_data, "1_chain11full1.csv"))
mat5 <- read.csv(matrices_data, "1_chain15full9.csv")
mat1 <- read.csv(paste0(matrices_data, "1_chain11full1.csv"))
mat5 <- read.csv(matrices_data, "1_chain15full9.csv")
mat1 <- read.csv(paste0(matrices_data, "1_chain11full1.csv"))
mat5 <- read.csv(paste0(matrices_data, "1_chain15full9.csv"))
mat1
mat1 <- read.csv(paste0(matrices_data, "1_chain11full1.csv"))
mat5 <- read.csv(paste0(matrices_data, "1_chain15full9.csv"))
top1 <- tsne(as.dist(mat1), perplexity =12)
top5 <- tsne(as.dist(mat2), perplexity =12)
colnames(top1) <- c("Xpos", "Ypos", "grouping")
pl <- ggplot(top, aes(x= Xpos, y = Ypos, color =grouping)) + geom_point(size= 10, alpa =0.1)
pl <- pl+  theme_void()  + theme(legend.position = "none") + scale_color_brewer(palette = "Set2")
pl
top1 <- tsne(as.dist(mat1), perplexity =12)
top5 <- tsne(as.dist(mat2), perplexity =12)
top1 <- cbind.data.frame(top, colnames(top1))
top5 <- cbind.data.frame(top5, colnames(top5))
colnames(top1) <- c("Xpos", "Ypos", "grouping")
pl <- ggplot(top, aes(x= Xpos, y = Ypos, color =grouping)) + geom_point(size= 10, alpa =0.1)
pl <- pl+  theme_void()  + theme(legend.position = "none") + scale_color_brewer(palette = "Set2")
pl
mat1 <- read.csv(paste0(matrices_data, "1_chain11full1.csv"))
mat5 <- read.csv(paste0(matrices_data, "1_chain15full9.csv"))
top1 <- tsne(as.dist(mat1), perplexity =12)
top5 <- tsne(as.dist(mat2), perplexity =12)
top1 <- cbind.data.frame(top, colnames(top1))
top5 <- cbind.data.frame(top5, colnames(top5))
top1 <- cbind.data.frame(top1, colnames(top1))
top1 <- cbind.data.frame(top1, colnames(top1))
top5 <- cbind.data.frame(top5, colnames(top5))
colnames(top1) <- c("Xpos", "Ypos", "grouping")
colnames(top2) <- c("Xpos", "Ypos", "grouping")
mat1 <- read.csv(paste0(matrices_data, "1_chain11full1.csv"))
mat5 <- read.csv(paste0(matrices_data, "1_chain15full9.csv"))
top1 <- tsne(as.dist(mat1), perplexity =12)
top5 <- tsne(as.dist(mat2), perplexity =12)
top1 <- cbind.data.frame(top1, colnames(top1))
top5 <- cbind.data.frame(top5, colnames(top5))
mat1 <- read.csv(paste0(matrices_data, "1_chain11full1.csv"))
mat5 <- read.csv(paste0(matrices_data, "1_chain15full9.csv"))
top1 <- tsne(as.dist(mat1), perplexity =12)
top5 <- tsne(as.dist(mat5), perplexity =12)
top1 <- cbind.data.frame(top1, colnames(top1))
top5 <- cbind.data.frame(top5, colnames(top5))
colnames(top1) <- c("Xpos", "Ypos", "grouping")
colnames(top5) <- c("Xpos", "Ypos", "grouping")
pl <- ggplot(top, aes(x= Xpos, y = Ypos)) + geom_point(size= 10, alpa =0.1)
pl <- pl+  theme_void()  + theme(legend.position = "none") + scale_color_brewer(palette = "Set2")
pl
pl <- ggplot(top1, aes(x= Xpos, y = Ypos)) + geom_point(size= 10, alpa =0.1)
pl <- pl+  theme_void()  + theme(legend.position = "none") + scale_color_brewer(palette = "Set2")
pl
pl <- ggplot(top1, aes(x= Xpos, y = Ypos)) + geom_point(size= 10, alpa =0.1)
top1
top1 <- cbind.data.frame(top1, colnames(top1))
top5 <- cbind.data.frame(top5, colnames(top5))
colnames(top1) <- c("Xpos", "Ypos", "grouping")
colnames(top5) <- c("Xpos", "Ypos", "grouping")
colnames(top1)
top1
mat1 <- read.csv(paste0(matrices_data, "1_chain11full1.csv"))
mat5 <- read.csv(paste0(matrices_data, "1_chain15full9.csv"))
top1 <- tsne(as.dist(mat1), perplexity =12)
top5 <- tsne(as.dist(mat5), perplexity =12)
top1 <- cbind.data.frame(top1, colnames(mat1))
top5 <- cbind.data.frame(top5, colnames(mat5))
colnames(top1) <- c("Xpos", "Ypos", "grouping")
colnames(top5) <- c("Xpos", "Ypos", "grouping")
pl <- ggplot(top, aes(x= Xpos, y = Ypos, color =grouping)) + geom_point(size= 10, alpa =0.1)
pl <- pl+  theme_void()  + theme(legend.position = "none") + scale_color_brewer(palette = "Set2")
pl
p1 <- ggplot(top1, aes(x= Xpos, y = Ypos, color =grouping)) + geom_point(size= 10, alpa =0.1)+ theme_void()  + theme(legend.position = "none") + scale_color_brewer(palette = "Set2")
p5 <- ggplot(top1, aes(x= Xpos, y = Ypos, color =grouping)) + geom_point(size= 10, alpa =0.1)+ theme_void()  + theme(legend.position = "none") + scale_color_brewer(palette = "Set2")
subplot(ggplotly(p1), ggplotly(p5))
library(plotly)
p1 <- ggplot(top1, aes(x= Xpos, y = Ypos, color =grouping)) + geom_point(size= 10, alpa =0.1)+ theme_void()  + theme(legend.position = "none") + scale_color_brewer(palette = "Set2")
p5 <- ggplot(top1, aes(x= Xpos, y = Ypos, color =grouping)) + geom_point(size= 10, alpa =0.1)+ theme_void()  + theme(legend.position = "none") + scale_color_brewer(palette = "Set2")
subplot(ggplotly(p1), ggplotly(p5))
p1 <- ggplot(top1, aes(x= Xpos, y = Ypos, color =grouping)) + geom_point(size= 10, alpa =0.1)+ theme_void()  + theme(legend.position = "none") + scale_color_brewer(palette = "Set2")
p5 <- ggplot(top5, aes(x= Xpos, y = Ypos, color =grouping)) + geom_point(size= 10, alpa =0.1)+ theme_void()  + theme(legend.position = "none") + scale_color_brewer(palette = "Set2")
subplot(ggplotly(p1), ggplotly(p5))
top1
p1 <- ggplot(top1, aes(x= Xpos, y = Ypos, color =grouping)) + geom_point(size= 5, alpa =0.1)+ theme_void()  + theme(legend.position = "none") + scale_color_brewer(palette = "Set2")
p5 <- ggplot(top5, aes(x= Xpos, y = Ypos, color =grouping)) + geom_point(size= 5, alpa =0.1)+ theme_void()  + theme(legend.position = "none") + scale_color_brewer(palette = "Set2")
subplot(ggplotly(p1), ggplotly(p5))
p1 <- ggplot(top1, aes(x= Xpos, y = Ypos, group =grouping)) + geom_point(size= 5, alpa =0.1)+ theme_void()  + theme(legend.position = "none") + scale_color_brewer(palette = "Set2")
p5 <- ggplot(top5, aes(x= Xpos, y = Ypos, group =grouping)) + geom_point(size= 5, alpa =0.1)+ theme_void()  + theme(legend.position = "none") + scale_color_brewer(palette = "Set2")
subplot(ggplotly(p1), ggplotly(p5))
animation video
library(plotly)
mat1 <- read.csv(paste0(matrices_data, "1_chain11full1.csv"))
mat5 <- read.csv(paste0(matrices_data, "1_chain15full9.csv"))
top1 <- tsne(as.dist(mat1), perplexity =5)
top5 <- tsne(as.dist(mat5), perplexity =5)
top1 <- cbind.data.frame(top1, colnames(mat1))
top5 <- cbind.data.frame(top5, colnames(mat5))
colnames(top1) <- c("Xpos", "Ypos", "grouping")
colnames(top5) <- c("Xpos", "Ypos", "grouping")
p1 <- ggplot(top1, aes(x= Xpos, y = Ypos, group =grouping)) + geom_point(size= 5, alpa =0.1)+ theme_void()  + theme(legend.position = "none") + scale_color_brewer(palette = "Set2")
p5 <- ggplot(top5, aes(x= Xpos, y = Ypos, group =grouping)) + geom_point(size= 5, alpa =0.1)+ theme_void()  + theme(legend.position = "none") + scale_color_brewer(palette = "Set2")
subplot(ggplotly(p1), ggplotly(p5))
p1 <- ggplot(top1, aes(x= Xpos, y = Ypos, group =grouping)) + geom_point(size= 5, alpha =0.1)+ theme_void()  + theme(legend.position = "none") + scale_color_brewer(palette = "Set2")
p5 <- ggplot(top5, aes(x= Xpos, y = Ypos, group =grouping)) + geom_point(size= 5, alpha =0.1)+ theme_void()  + theme(legend.position = "none") + scale_color_brewer(palette = "Set2")
subplot(ggplotly(p1), ggplotly(p5))
p1 <- ggplot(top1, aes(x= Xpos, y = Ypos, group =grouping)) + geom_point(size= 5, alpha =0.5)+ theme_void()  + theme(legend.position = "none") + scale_color_brewer(palette = "Set2")
p5 <- ggplot(top5, aes(x= Xpos, y = Ypos, group =grouping)) + geom_point(size= 5, alpha =0.5)+ theme_void()  + theme(legend.position = "none") + scale_color_brewer(palette = "Set2")
subplot(ggplotly(p1), ggplotly(p5))
p1 <- ggplot(top1, aes(x= Xpos, y = Ypos, group =grouping)) + geom_point(size= 15, alpha =0.5)+ theme_void()  + theme(legend.position = "none") + scale_color_brewer(palette = "Set2")
p5 <- ggplot(top5, aes(x= Xpos, y = Ypos, group =grouping)) + geom_point(size= 15, alpha =0.5)+ theme_void()  + theme(legend.position = "none") + scale_color_brewer(palette = "Set2")
subplot(ggplotly(p1), ggplotly(p5))
p1 <- ggplot(top1, aes(x= Xpos, y = Ypos, group =grouping)) + geom_point(size= 20, alpha =0.5)+ theme_void()  + theme(legend.position = "none") + scale_color_brewer(palette = "Set2")
p5 <- ggplot(top5, aes(x= Xpos, y = Ypos, group =grouping)) + geom_point(size= 20, alpha =0.5)+ theme_void()  + theme(legend.position = "none") + scale_color_brewer(palette = "Set2")
subplot(ggplotly(p1), ggplotly(p5))
library("papaja")     #papaja::apa6_pdf papaja::apa6_word
library(ggplot2)      #plotting
library(plotly)       #plotting
library(gridExtra)    #plotting (constructing multipanel plots)
library(ggExtra)      #plotting (adding distributions)
library(RColorBrewer) #plotting (color schemes)
library(dtw)          #dynamic time warping functions
library(effsize)      #effect sizes calculations
library(igraph)       #network graphing and analysis (network entropy)
library(cluster)      #cluster analysis (agglomerative clustering coefficient)
library(nlme)         #mixed linear regression
library(signal)       #for butterworth filter
library(pracma)       #for peak finding
library(r2glmm)       #mixed regression R^2
library(DescTools)    #Entropy calculation of the original motamedi data
library(entropy)      #Entropy calculations
library(EMAtools)     #cohen's d for mixed regression predictors
library(tsne)         #visualization for networks
library(cowplot)      #plotting aesthetics
library(scales)       #functions rescaling variables
library(stringr)          #string manipulation
library(parallelsugar)    #for parallel computing
library(clValid)      #clustering
library(MASS)         #clustering
library(raster)
#load in the finally edited time series example
mypng <- stack(paste0(plotfolder, "/MethodPlot/main_method_v3a.png"))
plotRGB(mypng,maxpixels=1e500000)
